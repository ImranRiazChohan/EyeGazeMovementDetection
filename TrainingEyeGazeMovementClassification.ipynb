{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainingEyeGazeMovementClassification.ipynb",
      "provenance": [],
      "mount_file_id": "1x01NeSyIvRH80cEKM64sLa0i9xcFAU6T",
      "authorship_tag": "ABX9TyPq5oOFNMs6l0us3iyp2dDO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImranRiazChohan/EyeGazeMovementDetection/blob/main/TrainingEyeGazeMovementClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MOD4Mzf_Qv0W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,Flatten,Dropout,Conv2D,MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "from tensorflow.keras.losses import categorical_crossentropy,sparse_categorical_crossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 \n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data From Directory\n",
        "Orignal_dir=\"/content/drive/MyDrive/Internship_TechroticsLab/EyeGazeMovementDetector/EyeData\"\n",
        "Train_data_dir=os.path.join(Orignal_dir,\"train\")\n",
        "train_center=os.path.join(Train_data_dir,\"center\")\n",
        "train_left=os.path.join(Train_data_dir,\"left\")\n",
        "train_right=os.path.join(Train_data_dir,\"right\")"
      ],
      "metadata": {
        "id": "BhL3Jq_RUrQ8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#left_data=os.listdir(train_left)\n",
        "#center_data=os.listdir(train_center)\n",
        "#right_data=os.listdir(train_right)"
      ],
      "metadata": {
        "id": "Eaf36vAudRuA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z1VGN7_9HfB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\" Left Data\",len(left_data),\"\\n\",\"Right Data\",\n",
        "#len(right_data),\"\\n\",\"Center Data\", \n",
        "#len(center_data))"
      ],
      "metadata": {
        "id": "eE1AyThAdZFg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_left_img=[]\n",
        "#for i in range(len(left_data)):\n",
        "#  path=train_left+\"/\"+left_data[i]\n",
        "#  img=cv2.imread(path)\n",
        "#  cvt_img=cv2.resize(img,(64,56),3)\n",
        "#  train_left_img.append(cvt_img)"
      ],
      "metadata": {
        "id": "A0dWAhgCJKfs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_left_img[0].shape"
      ],
      "metadata": {
        "id": "v9YUPufRT6BK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_right_img=[]\n",
        "#for i in range(len(right_data)):\n",
        "#  path=train_right+\"/\"+right_data[i]\n",
        "#  img=cv2.imread(path)\n",
        "#  cvt_img=cv2.resize(img,(64,56),3)\n",
        "#  train_right_img.append(cvt_img)\n"
      ],
      "metadata": {
        "id": "HYTJfmiBLzs5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_center_img=[]\n",
        "#for i in range(len(center_data)):\n",
        "#  path=train_center+\"/\"+center_data[i]\n",
        "#  img=cv2.imread(path)\n",
        "#  cvt_img=cv2.resize(img,(64,56),3)\n",
        "#  train_center_img.append(cvt_img)"
      ],
      "metadata": {
        "id": "1lh9TlHDLz-r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(0,5):\n",
        "#  cv2_imshow(train_left_img[i])\n",
        "#  print(train_left_img[i].shape)"
      ],
      "metadata": {
        "id": "3bJnyYmXLPyD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(0,5):\n",
        "#  cv2_imshow(train_right_img[i])\n",
        "#  print(train_right_img[i].shape)"
      ],
      "metadata": {
        "id": "q8PfmqOCLxkd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range (0,5):\n",
        "#  cv2_imshow(train_center_img[i])\n",
        "#  print(train_center_img[i].shape)"
      ],
      "metadata": {
        "id": "Umt3BCyeYwnY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_dir=os.path.join(Orignal_dir,\"test\")\n",
        "test_center_data=os.path.join(test_data_dir,\"center\")\n",
        "test_left_data=os.path.join(test_data_dir,\"left\")\n",
        "test_right_data=os.path.join(test_data_dir,\"right\")"
      ],
      "metadata": {
        "id": "yUzSHHec7Blz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_left=os.listdir(test_left_data)\n",
        "#test_right=os.listdir(test_right_data)\n",
        "#est_center=os.listdir(test_center_data)"
      ],
      "metadata": {
        "id": "PvbSKNHb8JTz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"left:{}\\nright:{}\\ncenter:{}\".format(len(test_left),len(test_right),len(test_center)))"
      ],
      "metadata": {
        "id": "MCjqRa0z8gaU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_center_img=[]\n",
        "#test_right_img=[]\n",
        "#test_left_img=[]\n",
        "\n",
        "#for i in range(len(test_center)):\n",
        "#  path=test_center_data+\"/\"+test_center[i]\n",
        "#  img_center=cv2.imread(path)\n",
        "#  resize_img=cv2.resize(img_center,(64,56),3)\n",
        "#  test_center_img.append(resize_img)\n",
        "#for i in range(len(test_left)):\n",
        "#  path=test_left_data+\"/\"+test_left[i]\n",
        "#  img_left=cv2.imread(path)\n",
        "#  resize_img=cv2.resize(img_left,(64,56),3)\n",
        "#  test_left_img.append(resize_img)\n",
        "#for i in range(len(test_right)):\n",
        "#  path=test_right_data+\"/\"+test_right[i]\n",
        "#  img_right=cv2.imread(path)\n",
        "#  resize_img=cv2.resize(img_right,(64,56),3)\n",
        "#  test_right_img.append(resize_img)\n"
      ],
      "metadata": {
        "id": "riPQNbEkcKKt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path=test_center_data+\"/\"+test_center[0]\n",
        "#img=cv2.imread(path)\n",
        "#img.shape"
      ],
      "metadata": {
        "id": "2HJ9tAVtIDCf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen=ImageDataGenerator(rotation_range=10,\n",
        "                                  rescale=1./255,\n",
        "                                  width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1,\n",
        "                                  shear_range=0.1,\n",
        "                                  zoom_range=0.1,\n",
        "                                  fill_mode=\"nearest\")\n",
        "test_data_gen=ImageDataGenerator(rescale=1./255)\n",
        "valid_data_gen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "dwxtl6gB84Rk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data_gen.flow_from_directory(Train_data_dir)\n",
        "#test_data_gen.flow_from_directory(test_data_dir)"
      ],
      "metadata": {
        "id": "k6szinX2AlzY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=train_data_gen.flow_from_directory(Train_data_dir,target_size=(64,56),batch_size=16,color_mode=\"grayscale\",class_mode=\"categorical\")\n",
        "test_set=test_data_gen.flow_from_directory(test_data_dir,target_size=(64,56),batch_size=16,color_mode=\"grayscale\",class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF-i14igAsO8",
        "outputId": "fa0e3464-2980-4859-9e85-e15f85005046"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3622 images belonging to 3 classes.\n",
            "Found 831 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hKSWHqcCkJP",
        "outputId": "e4b0a91c-af6a-4f72-e762-2ad50cdacfae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'center': 0, 'left': 1, 'right': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),strides=1,padding=\"same\",input_shape=(64,56,1),activation=\"relu\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(256,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512,activation=\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(512,activation=\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "model.add(Dense(3,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "-8647d8ipEn9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zq05GW0Z_yG",
        "outputId": "f71c8129-37d0-4b94-a9ac-7a0a2a0ff69f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 64, 56, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 32, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 28, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 14, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 7, 256)         295168    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 4, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               1573376   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,225,667\n",
            "Trainable params: 2,225,539\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])"
      ],
      "metadata": {
        "id": "phKM83W2aSgQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback=EarlyStopping(monitor='val_loss',patience=2)"
      ],
      "metadata": {
        "id": "1GPmTrrqbe1R"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_set,epochs=8,validation_data=test_set,callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUsrMsoqb9F_",
        "outputId": "5ecafd0b-758b-449f-b27f-934fc82b3875"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "227/227 [==============================] - 1459s 6s/step - loss: 0.1270 - acc: 0.9586 - val_loss: 0.6517 - val_acc: 0.9591\n",
            "Epoch 2/8\n",
            "227/227 [==============================] - 14s 63ms/step - loss: 0.0439 - acc: 0.9876 - val_loss: 0.0576 - val_acc: 0.9964\n",
            "Epoch 3/8\n",
            "227/227 [==============================] - 14s 62ms/step - loss: 0.0344 - acc: 0.9912 - val_loss: 0.0120 - val_acc: 0.9976\n",
            "Epoch 4/8\n",
            "227/227 [==============================] - 14s 61ms/step - loss: 0.0355 - acc: 0.9912 - val_loss: 0.0505 - val_acc: 0.9807\n",
            "Epoch 5/8\n",
            "227/227 [==============================] - 14s 61ms/step - loss: 0.0206 - acc: 0.9956 - val_loss: 0.0912 - val_acc: 0.9928\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d14d94490>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Internship_TechroticsLab/eyegaze.h5\")"
      ],
      "metadata": {
        "id": "wgdaiwYFl59p"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4lKdOn38QYdi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}